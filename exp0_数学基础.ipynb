{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习的数学基础\n",
    "\n",
    "## 1 符号系统\n",
    "\n",
    "### 1.1 数与数组\n",
    "* $a \\in \\mathbb{R}$： 标量（实数）\n",
    "* $\\bm{a} \\in \\mathbb{R^{n}}$：向量（本篇向量均特指列向量）\n",
    "* $\\bm{A} \\in \\mathbb{R^{m \\times n}}$：矩阵\n",
    "* $\\bf{A} \\in \\mathbb{R^{b \\times c \\times m \\times n \\times ...}}$：张量（batch 大小为 b，通道数为 c，行为 m，列为 n，...）\n",
    "* $\\bm{I_n}$：n 行 n 列的单位矩阵\n",
    "* $\\bm{I}$：维度蕴含于上下文的单位矩阵\n",
    "* $diag(\\bm{a})$：对角方阵，其中对角元素由向量 $\\bm{a}$ 给定\n",
    "\n",
    "### 1.2 集合\n",
    "* $\\mathbb{A}$：集合\n",
    "* $\\mathbb{R}$：实数集\n",
    "* $\\{0,1,\\cdots,n\\}$：包含从 0 到 n 的所有整数的集合\n",
    "* $[a,b]$：包含 $a$ 和 $b$ 的实数区间\n",
    "* $(a,b]$：不包含 $a$ 但包含 $b$ 的实数区间\n",
    "* $\\mathbb{A} \\backslash \\mathbb{B}$：集合 $\\mathbb{A}$ 与集合 $\\mathbb{B}$ 的差集\n",
    "\n",
    "### 1.3 索引\n",
    "* $a_i$：向量 $\\bm{a}$ 的第 $i$ 个元素，索引从 1 开始\n",
    "* $a_{-i}$：除了第 $i$ 个元素，向量的所有元素\n",
    "* $A_{i,j}$：矩阵 $\\bm{A}$ 的 ${i,j}$ 元素\n",
    "* $\\bm{A}_{i,:}$：矩阵 $\\bm{A}$ 的第 ${i}$ 行\n",
    "* $\\bm{A}_{:,j}$：矩阵 $\\bm{A}$ 的第 ${j}$ 列\n",
    "* ${A}_{i,j,k}$：3 维张量 $\\bm{A}$ 的 $({i,j,k})$ 元素\n",
    "* $\\mathbf{A}_{:,:,i}$：3 维张量的 2 维切片\n",
    "\n",
    "### 1.4 线性代数\n",
    "* $\\bm{A}^{T}$：矩阵 $\\bm{A}$ 的转置\n",
    "* $\\bm{A}^{-1}$：$\\bm{A}$ 的逆\n",
    "* $\\bm{A} \\odot \\bm{B}$：$\\bm{A}$ 和 $\\bm{B}$ 的逐元素乘积\n",
    "* $\\det (\\bm{A})$：$\\bm{A}$ 的行列式\n",
    "\n",
    "### 1.5 微积分\n",
    "* $\\frac{dy}{dx}$：$y$ 关于 $x$ 的导数\n",
    "* $\\frac{\\partial y}{\\partial x}$：$y$ 关于 $x$ 的偏导数\n",
    "* $\\nabla_{\\bm{x}}y$：$y$ 关于 $\\bm{x}$ 的梯度\n",
    "* $\\nabla_{\\bm{X}}y$：$y$ 关于 $\\bm{X}$ 的矩阵导数\n",
    "* $\\nabla_{\\bf{X}}y$：$y$ 关于 $\\bf{X}$ 求导后的张量\n",
    "* $\\frac{\\partial{y}}{\\partial{\\bm x}}$：$f:\\mathbb{R^{n}} \\to \\mathbb{R^{m}}$ 的 Jacobian 矩阵 $\\bm{J} \\in \\mathbb{R^{m \\times n}}$\n",
    "* $\\nabla_{\\bm x}^{2}f(\\bm x)$ or $\\bm{H}(f)(\\bm x)$：$f$ 在 $\\bm x$ 处的 Hessian 矩阵\n",
    "* $\\int f(\\bm x)d \\bm x$：$\\bm x$ 整个域上的定积分\n",
    "* $\\int_{\\mathbb{S}} f(\\bm x)d \\bm x$：集合 $\\mathbb S$ 上关于 $\\bm x$ 的定积分\n",
    "\n",
    "### 1.6 函数\n",
    "* $f: \\mathbb{A} \\to \\mathbb{B}$：定义域为 $\\mathbb{A}$，值域为 $\\mathbb{B}$ 的函数 $f$\n",
    "* $f \\circ g$：$f$ 和 $g$ 的复合\n",
    "* $f(\\bm x;\\bm\\theta)$：由 $\\bm\\theta$ 参数化，关于 $\\bm x$ 的函数（有时为了简化表示，会忽略 $\\bm\\theta$ 而记为 $f(\\bm x)$）\n",
    "* $\\left\\|\\bm{x}\\right\\|_p$：$\\bm x$ 的 $L^p$ 范数\n",
    "* $\\left\\|\\bm{x}\\right\\|$：$\\bm x$ 的 $L^2$ 范数\n",
    "\n",
    "当自变量为标量的函数 $f$ 应用到一个向量、矩阵或张量时，表示逐元素地将 $f$ 应用。例如，$\\bf{Y} = $ $f(\\bf X)$，则对于所有合法的 $i,j,k$，$Y_{i,j,k}=f(X_{i,j,k})$\n",
    "\n",
    "### 1.7 数据集和分布\n",
    "* $p_{data}$：数据生成分布\n",
    "* $\\hat{p}_{train}$：由训练集定义的经验分布\n",
    "* $\\mathbb{X}$：训练样本的集合，第一个维度（比如矩阵的行数）表示样本个数\n",
    "* $\\bm{x}^{(i)}$：数据集的第 $i$ 个样本（输入）\n",
    "* $y^{(i)}$ 或 $\\bm{y}^{(i)}$：监督学习中与 $\\bm{x}^{(i)}$ 关联的目标\n",
    "* $\\bm{X}$：$m \\times n$ 的矩阵，其中行 $\\bm{X}_{i,:}$ 为输入样本 $\\bm x^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 微积分必要知识\n",
    "### 2.1 函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ 的梯度\n",
    "LaTex 各种矩阵表示见：https://zhuanlan.zhihu.com/p/266267223\n",
    "$$\n",
    "\\bm{x} = \\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\n",
    "\\end{bmatrix},\n",
    "\\nabla_{\\bm{x}} f = \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### 2.2 函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ 的 Hessian 矩阵（二阶偏导矩阵）\n",
    "$$\n",
    "\\bm{H}(f)(\\bm{x}) = \\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n",
    "\\end{bmatrix}_{n \\times n}\n",
    "$$\n",
    "\n",
    "### 2.3 向量函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}^{m}$ 的 Jacobian 矩阵（一阶偏导矩阵）\n",
    "$$\n",
    "\\bm{x} = \\left [ x_1,x_2,\\cdots,x_n\\right ]^{T},\n",
    "\\bm{f}(\\bm{x}) = \\left [ f_1(\\bm{x}),f_2(\\bm{x}),\\cdots,f_m(\\bm{x})\\right ]^{T}\n",
    "\\\\\n",
    "\\bm{J}_{m \\times n} = \\begin{bmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n",
    "\\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\cdots & \\frac{\\partial f_2}{\\partial x_n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial x_1} & \\frac{\\partial f_m}{\\partial x_2} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{bmatrix}_{m \\times n}\n",
    "$$\n",
    "\n",
    "### 2.4 向量乘法的求导\n",
    "* $y = \\bm{w}^{T}\\bm{x}$，$\\nabla_{\\bm{w}}y = \\bm{x}$，$\\nabla_{\\bm{x}}y = \\bm{w}$\n",
    "\n",
    "### 2.5 矩阵乘向量的求导\n",
    "* $\\bm{y} = \\bm{A}\\bm{x}$，$\\bm{J} = \\nabla_{\\bm{x}}\\bm{y} = \\bm{A}_{m \\times n}$\n",
    "\n",
    "### 2.6 二次型 $y = \\bm{x}^T A \\bm{x}$ 的求导\n",
    "* $\\nabla_{\\bm{x}}y = (\\bm{A}^T+\\bm{A})\\bm{x}$\n",
    "* 证明：\n",
    "    \n",
    "    $y \\in \\mathbb{R}, \\bm{A} \\in \\mathbb{R}^{n \\times n}, \\bm{x} \\in \\mathbb{R}^{n}$，<br>\n",
    "    $$\n",
    "    \\bm{A}\\bm{x} = \\sum_{j=1}^{n} x_j \\bm{A_{:,j}} = \\left [\\sum_{j=1}^{n} A_{1,j}x_j, \\sum_{j=1}^{n} A_{2,j}x_j, \\cdots, \\sum_{j=1}^{n} A_{n,j}x_j\\right ]^T,\n",
    "    $$\n",
    "    $$\n",
    "    y = \\bm{x}^T \\bm{A} \\bm{x} = \\sum_{i=1}^{n}\\left ( x_i\\sum_{j=1}^{n} A_{i,j}x_j\\right ) = \\sum_{i=1}^{n}\\sum_{j=1}^{n} A_{i,j}x_ix_j,\n",
    "    $$\n",
    "    $$\n",
    "    \\frac{\\partial y}{\\partial x_k} = \\sum_{i=1}^{n} A_{i,k}x_i + \\sum_{j=1}^{n} A_{k,j}x_j,\n",
    "    $$\n",
    "    $$\n",
    "    \\nabla_{\\bm{x}}y = \\begin{bmatrix}\n",
    "    \\sum_{i=1}^{n} A_{i,1}x_i + \\sum_{j=1}^{n} A_{1,j}x_j, \\\\\n",
    "    \\sum_{i=1}^{n} A_{i,2}x_i + \\sum_{j=1}^{n} A_{2,j}x_j, \\\\\n",
    "    \\vdots \\\\\n",
    "    \\sum_{i=1}^{n} A_{i,n}x_i + \\sum_{j=1}^{n} A_{n,j}x_j\n",
    "    \\end{bmatrix}_{n \\times 1} = \\bm{A}^T\\bm{x} + \\bm{A}\\bm{x}\n",
    "    $$\n",
    "    若 $\\bm A$ 是对称阵，则 $\\nabla_{\\bm{x}}y = 2\\bm A \\bm x$。<br>\n",
    "    证明结束。\n",
    "    \n",
    "\n",
    "### 2.7 $L^2$ 范数的求导\n",
    "* $y = \\left\\| \\bm{A}\\bm{x}\\right\\|^2 = (\\bm{A}\\bm{x})^T\\bm{A}\\bm{x} = \\bm{x}^T\\bm{A}^T\\bm{A}\\bm{x}$。$\\nabla_{\\bm{x}}y = 2\\bm{A}^T\\bm{A}\\bm{x}$，是$n \\times 1$ 维的向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 线性代数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 概率和信息论"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_vtuber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
